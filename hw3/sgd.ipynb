{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    x = x/x.max()\n",
    "    e_x = np.exp(x)\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def test_loss(x_in, y_in, weights1, weights2, biases1, biases2):\n",
    "        out1_temp = np.matmul(weights1.T, x_in[:,:])+biases1\n",
    "        out1 = sigmoid(out1_temp)\n",
    "        out2_temp = np.matmul(weights2.T, out1)+biases2\n",
    "        out2 = sigmoid(out2_temp)\n",
    "        loss = []\n",
    "        for iter in range(out2.shape[1]):\n",
    "            loss.append(cross_entropy(out2[:, iter], y_in[:, iter]))\n",
    "        return np.mean(loss)\n",
    "\n",
    "def pred_out(x_in, y_in, weights1, weights2, biases1, biases2):\n",
    "        out1_temp = np.matmul(weights1.T, x_in[:,:])+biases1\n",
    "        out1 = sigmoid(out1_temp)\n",
    "        out2_temp = np.matmul(weights2.T, out1)+biases2\n",
    "        out2 = sigmoid(out2_temp)\n",
    "        return out2\n",
    "\n",
    "def acc_out(x_in, y_in, weights1, weights2, biases1, biases2):\n",
    "    pred = pred_out(x_in, y_in, weights1, weights2, biases1, biases2)\n",
    "    sum_acc = 0\n",
    "    for iter in range(pred.shape[1]):\n",
    "#         print(iter)\n",
    "        sum_acc+=(np.argmax(pred[:, iter])==np.argmax(y_in[:, iter]))\n",
    "    return sum_acc/y_in.shape[1]\n",
    "\n",
    "def cross_entropy(predictions, targets, epsilon=1e-5):\n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    ce = - np.mean(np.multiply(np.log(predictions),targets)) \n",
    "    return ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load and segregate the data\n",
    "iris = genfromtxt('iris.csv', delimiter=',')\n",
    "np.random.shuffle(iris)\n",
    "x_in = iris[:, 0:4]\n",
    "\n",
    "y_in = np.zeros(iris[:, 0:3].shape)\n",
    "for iter in range(iris.shape[0]):\n",
    "    y_in[iter, :] = [0, 0, 0]\n",
    "    y_in[iter, int(iris[iter, 4])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_in[0:int(x_in.shape[0]*0.7), :]\n",
    "y_train = y_in[0:int(x_in.shape[0]*0.7), :]\n",
    "\n",
    "x_test = x_in[int(x_in.shape[0]*0.7):x_in.shape[0], :]\n",
    "y_test = y_in[int(x_in.shape[0]*0.7):x_in.shape[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 10)\n",
      "(10, 3)\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 3000\n",
    "\n",
    "weights1 = np.random.uniform(1e-8, 1e-3,size=(x_in.shape[1], hidden_size))\n",
    "weights2 = np.random.normal(1e-8, 1e-3,size=(hidden_size, y_in.shape[1]))\n",
    "print(weights1.shape)\n",
    "print(weights2.shape)\n",
    "biases1 = np.random.normal(1e-8, 1e-3,size=(hidden_size, 1))\n",
    "biases2 = np.random.normal(1e-8, 1e-3,size=(y_in.shape[1], 1))\n",
    "\n",
    "x_train = np.matrix(x_train)\n",
    "x_train = x_train.T\n",
    "y_train = np.matrix(y_train)\n",
    "y_train = y_train.T\n",
    "\n",
    "x_test = np.matrix(x_test)\n",
    "x_test = x_test.T\n",
    "y_test = np.matrix(y_test)\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss :  0.23092058758182965\n",
      "epoch_num :  1\n",
      "test_loss :  0.23091904946120462\n",
      "epoch_num :  51\n",
      "test_loss :  0.2308931430090447\n",
      "epoch_num :  101\n",
      "test_loss :  0.2306257086987965\n",
      "epoch_num :  151\n",
      "test_loss :  0.22966695249246655\n",
      "epoch_num :  201\n",
      "test_loss :  0.22720913331129813\n",
      "epoch_num :  251\n",
      "test_loss :  0.22213177944810994\n",
      "epoch_num :  301\n",
      "test_loss :  0.21221703353115495\n",
      "epoch_num :  351\n",
      "test_loss :  0.19379117353053513\n",
      "epoch_num :  401\n",
      "test_loss :  0.16587034894061106\n",
      "epoch_num :  451\n",
      "test_loss :  0.13672266778060121\n",
      "epoch_num :  501\n",
      "test_loss :  0.11633510274868793\n",
      "epoch_num :  551\n",
      "test_loss :  0.10419852852218518\n",
      "epoch_num :  601\n",
      "test_loss :  0.09536571923172699\n",
      "epoch_num :  651\n",
      "test_loss :  0.08737877916265444\n",
      "epoch_num :  701\n",
      "test_loss :  0.07900728506394168\n",
      "epoch_num :  751\n",
      "test_loss :  0.07141265435476697\n",
      "epoch_num :  801\n",
      "test_loss :  0.06318464494505135\n",
      "epoch_num :  851\n",
      "test_loss :  0.05427679982549889\n",
      "epoch_num :  901\n",
      "test_loss :  0.04546365603711378\n",
      "epoch_num :  951\n",
      "test_loss :  0.037744708128558534\n",
      "epoch_num :  1001\n"
     ]
    }
   ],
   "source": [
    "accuracies_train = []\n",
    "accuracies_test = []\n",
    "losses = []\n",
    "test_losses = []\n",
    "for epoch_num in range(num_epochs):\n",
    "    if epoch_num%50==1:\n",
    "        print(\"test_loss : \", test_losses[-1])\n",
    "        print(\"epoch_num : \", epoch_num)\n",
    "    for sample_num in range(x_train.shape[1]):\n",
    "#         print(\"sample_num : \", sample_num)\n",
    "        #Forward propagation\n",
    "        out1_temp = np.matmul(weights1.T, x_train[:,sample_num])+biases1\n",
    "        out1 = sigmoid(out1_temp)\n",
    "        out2_temp = np.matmul(weights2.T, out1)+biases2\n",
    "        out2 = softmax(out2_temp)\n",
    "        #Back-propogation\n",
    "        error_out = out2-y_train[:, sample_num]\n",
    "        err_2 = np.matrix(error_out)\n",
    "        grad_2 = np.matmul(out1, err_2.T)\n",
    "        err_1 = np.multiply(np.matmul(weights2, err_2), np.multiply(out1, np.ones(out1.shape)-out1))\n",
    "        grad_1 = np.multiply(x_train[:, sample_num], err_1.T)\n",
    "        #Updating the weights\n",
    "        biases1 = biases1 - learning_rate*err_1\n",
    "        biases2 = biases2 - learning_rate*err_2\n",
    "        weights1 = weights1-learning_rate*grad_1\n",
    "        weights2 = weights2-learning_rate*grad_2\n",
    "        #Updating the accuracy and loss\n",
    "        #End of for loop\n",
    "#     print(\"accuracy : \", np.mean(acc_arr))\n",
    "    test_losses.append(test_loss(x_test, y_test, weights1, weights2, biases1, biases2))\n",
    "    accuracies_test.append(acc_out(x_test, y_test, weights1, weights2, biases1, biases2))\n",
    "    accuracies_train.append(acc_out(x_train, y_train, weights1, weights2, biases1, biases2))\n",
    "    losses.append(test_loss(x_train, y_train, weights1, weights2, biases1, biases2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.subplot(211)\n",
    "plt.plot(losses, label = 'train_loss')\n",
    "plt.plot(test_losses, label = 'test_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# plt.subplot(212)\n",
    "plt.plot(accuracies_train, label = 'accuracies_train')\n",
    "plt.plot(accuracies_test, label = 'accuracies_test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_out(x_train, y_train, weights1, weights2, biases1, biases2))\n",
    "print(acc_out(x_test, y_test, weights1, weights2, biases1, biases2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
